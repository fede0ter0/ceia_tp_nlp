{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## TP 1 - Vectorización\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Federico Otero <br>fede.e.otero@gmail.com<br>Cohorte 11"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[],"source":["def get_vocabulary(corpus):\n","    vocabulary = set()\n","    docs = dict()\n","    for i,d in enumerate(corpus):\n","        _doc = d.split(' ')\n","        #_doc.sort()\n","        docs[i] = _doc\n","        vocabulary = vocabulary | set(_doc)\n","        _voc = list(vocabulary)\n","        _voc.sort()\n","    return _voc, docs"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["voc, docs = get_vocabulary(corpus)\n","voc"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["{0: ['que', 'dia', 'es', 'hoy'],\n"," 1: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'],\n"," 2: ['martes', 'muchas', 'gracias']}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["docs"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def one_hot_encoding_matrix(corpus):\n","    voc, docs = get_vocabulary(corpus)\n","    # get unique terms by document\n","    for d in docs.keys():\n","        docs[d] = set(docs[d])\n","    \n","    n_terms = len(voc)\n","    n_docs = (corpus.shape)[0]\n","    one_hot_encoding_matrix = np.zeros((n_docs,n_terms))\n","    for i,row in enumerate(one_hot_encoding_matrix):\n","        for j,col in enumerate(row):\n","            _doc = docs[i]\n","            one_hot_encoding_matrix[i,j]=1 if (voc[j] in list(_doc)) else 0\n","    return one_hot_encoding_matrix"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["ohe = one_hot_encoding_matrix(corpus)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary ['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n","------------------------------------------------------------------------------------\n","One Hot Encoding Matrix: \n","[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"," [1. 1. 1. 1. 0. 1. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n","------------------------------------------------------------------------------------\n"]}],"source":["print(f'Vocabulary {voc}')\n","print('-'*84)\n","print(f'One Hot Encoding Matrix: \\n{ohe}')\n","print('-'*84)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[],"source":["def frequencies_matrix(corpus):\n","    voc, docs = get_vocabulary(corpus)\n","    n_terms = len(voc)\n","    n_docs = (corpus.shape)[0]\n","\n","    freqs = np.zeros((n_docs,n_terms))\n","    for i,row in enumerate(freqs):\n","        for j,col in enumerate(row):\n","            _term = voc[j]\n","            _doc = docs[i]\n","            freq = _doc.count(_term)\n","            freqs[i,j]+=freq\n","    return freqs"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["freq_matrix = frequencies_matrix(corpus)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary ['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n","------------------------------------------------------------------------------------\n","Frequency Matrix: \n","[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"," [1. 1. 1. 1. 0. 1. 2. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n","------------------------------------------------------------------------------------\n"]}],"source":["print(f'Vocabulary {voc}')\n","print('-'*84)\n","print(f'Frequency Matrix: \\n{freq_matrix}')\n","print('-'*84)"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":["def get_idf_vector(corpus):\n","    voc, docs = get_vocabulary(corpus)\n","   \n","    n_terms = len(voc)\n","    n_docs = (corpus.shape)[0]\n","    idf_vector = np.zeros((n_terms))\n","\n","    for i, e in enumerate(idf_vector):\n","        term=voc[i]\n","        df=0\n","        for n in range(n_docs):\n","            if term in docs[n]: df+=1\n","        if df>0: idf_vector[i] = np.log10([n_docs/df])\n","    return idf_vector"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["idf_vector = get_idf_vector(corpus)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary ['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n","------------------------------------------------------------------------------------\n","IDF Vector: \n","\n","[0.47712125 0.17609126 0.47712125 0.17609126 0.47712125 0.17609126\n"," 0.17609126 0.47712125 0.47712125]\n","------------------------------------------------------------------------------------\n"]}],"source":["print(f'Vocabulary {voc}')\n","print('-'*84)\n","print(f'IDF Vector: \\n\\n{idf_vector}')\n","print('-'*84)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def get_tf_idf_matrix(corpus):\n","    freq_matrix = frequencies_matrix(corpus)\n","    idf_vector = get_idf_vector(corpus)\n","    tf_idf_matrix = freq_matrix * idf_vector.reshape(1,-1)\n","    return tf_idf_matrix"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["tf_idf_matrix = get_tf_idf_matrix(corpus)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary ['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n","------------------------------------------------------------------------------------\n","Documents {0: ['que', 'dia', 'es', 'hoy'], 1: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], 2: ['martes', 'muchas', 'gracias']}\n","------------------------------------------------------------------------------------\n","Freq Matrix: \n","\n","[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"," [1. 1. 1. 1. 0. 1. 2. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n","------------------------------------------------------------------------------------\n","IDF Vector: \n","\n","[0.47712125 0.17609126 0.47712125 0.17609126 0.47712125 0.17609126\n"," 0.17609126 0.47712125 0.47712125]\n","------------------------------------------------------------------------------------\n","TF-IDF Matrix: \n","\n","[[0.         0.17609126 0.         0.17609126 0.         0.17609126\n","  0.         0.         0.47712125]\n"," [0.47712125 0.17609126 0.47712125 0.17609126 0.         0.17609126\n","  0.35218252 0.         0.        ]\n"," [0.         0.         0.         0.         0.47712125 0.\n","  0.17609126 0.47712125 0.        ]]\n","------------------------------------------------------------------------------------\n"]}],"source":["print(f'Vocabulary {voc}')\n","print('-'*84)\n","print(f'Documents {docs}')\n","print('-'*84)\n","print(f'Freq Matrix: \\n\\n{freq_matrix}')\n","print('-'*84)\n","print(f'IDF Vector: \\n\\n{idf_vector}')\n","print('-'*84)\n","print(f'TF-IDF Matrix: \\n\\n{tf_idf_matrix}')\n","print('-'*84)"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["def cosine_similarity(corpus, _id):\n","    voc, docs = get_vocabulary(corpus)\n","    tf_idf = get_tf_idf_matrix(corpus)\n","    row = tf_idf[_id,:]\n","    indexes_to_explore = range((tf_idf.shape)[0])\n","    idxs = set(indexes_to_explore) - set([_id])\n","    _idxs = list(idxs)\n","    doc = np.array(row)\n","    cosines = dict()\n","    for i in _idxs:\n","        doc_to_compare = tf_idf[i,:]\n","        cosines[i] = np.dot(doc, doc_to_compare) / (np.linalg.norm(doc) * (np.linalg.norm(doc_to_compare)))\n","    cosines_sorted = sorted(cosines, reverse=True)\n","    _docs = [v for k,v in docs.items() if k in cosines_sorted]\n","    return _docs"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["similar_docs = cosine_similarity(corpus,1)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["voc, docs = get_vocabulary(corpus)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary ['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n","------------------------------------------------------------------------------------\n","Documents {0: ['que', 'dia', 'es', 'hoy'], 1: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], 2: ['martes', 'muchas', 'gracias']}\n","------------------------------------------------------------------------------------\n","TF-IDF Matrix: \n","\n","[[0.         0.17609126 0.         0.17609126 0.         0.17609126\n","  0.         0.         0.47712125]\n"," [0.47712125 0.17609126 0.47712125 0.17609126 0.         0.17609126\n","  0.35218252 0.         0.        ]\n"," [0.         0.         0.         0.         0.47712125 0.\n","  0.17609126 0.47712125 0.        ]]\n","------------------------------------------------------------------------------------\n","Most similar documents to ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']:\n","['que', 'dia', 'es', 'hoy']\n","['martes', 'muchas', 'gracias']\n"]}],"source":["print(f'Vocabulary {voc}')\n","print('-'*84)\n","print(f'Documents {docs}')\n","print('-'*84)\n","print(f'TF-IDF Matrix: \\n\\n{tf_idf_matrix}')\n","print('-'*84)\n","print(f'Most similar documents to {docs[1]}:')\n","for sd in similar_docs:\n","    print(sd)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
